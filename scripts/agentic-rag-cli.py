#!/usr/bin/env python3
"""
Agentic RAG CLI - Intelligent Conversational AI with Smart Synthesis
Enhanced conversational workflows with intelligent reasoning and synthesis

Key Features:
- Intelligent content synthesis and summarization
- Smart response generation based on search results
- Agentic question-answer generation
- Enhanced conversational workflows
- Real vault content with AI-powered insights
- Cost-optimized reasoning
"""

import asyncio
import logging
import sys
import os
import time
import json
import re
import random
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple
import hashlib
from datetime import datetime
from collections import deque

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class AgenticRAGCLI:
    """Agentic RAG CLI with intelligent reasoning and synthesis"""
    
    def __init__(self):
        # Real vault path
        self.vault_path = Path(r"D:\Nomade Milionario")
        self.chroma_db_path = Path("./data/chroma")
        self.collection_name = "enhanced_semantic_engine"
        
        # Performance tracking
        self.query_cache = {}
        self.synthesis_cache = {}  # Cache for synthesis responses
        self.performance_metrics = {
            "total_queries": 0,
            "total_search_time": 0.0,
            "total_synthesis_time": 0.0,
            "cache_hits": 0,
            "cache_misses": 0,
            "synthesis_calls": 0,
            "conversations": 0,
            "context_switches": 0
        }
        
        # Conversation management
        self.conversation_history = deque(maxlen=50)
        self.current_context = {
            "topic": None,
            "last_search_results": [],
            "user_interests": set(),
            "conversation_flow": "exploration",
            "last_synthesis": None
        }
        self.session_id = f"agentic_rag_{int(time.time())}"
        
        # Vault content cache
        self.vault_content = {}
        self.file_metadata = {}
        
        # Intelligent synthesis templates
        self.synthesis_templates = {
            "performance": {
                "keywords": ["performance", "otimiza√ß√£o", "produtividade", "efici√™ncia", "melhores pr√°ticas"],
                "response_patterns": [
                    "Com base nos documentos encontrados sobre {topic}, aqui est√£o as principais estrat√©gias de otimiza√ß√£o:",
                    "Analisando o conte√∫do sobre {topic}, identifiquei as seguintes abordagens para melhorar performance:",
                    "Os documentos mostram v√°rias t√©cnicas eficazes para {topic}:"
                ],
                "synthesis_patterns": [
                    "1. **Estrat√©gias Principais**: {main_strategies}",
                    "2. **Ferramentas Recomendadas**: {recommended_tools}",
                    "3. **Melhores Pr√°ticas**: {best_practices}",
                    "4. **Pr√≥ximos Passos**: {next_steps}"
                ]
            },
            "machine_learning": {
                "keywords": ["machine learning", "ml", "ia", "intelig√™ncia artificial", "algoritmos", "dados"],
                "response_patterns": [
                    "Encontrei informa√ß√µes valiosas sobre {topic} nos seus documentos:",
                    "Com base no conte√∫do sobre {topic}, aqui est√£o os conceitos principais:",
                    "Os documentos revelam insights importantes sobre {topic}:"
                ],
                "synthesis_patterns": [
                    "1. **Conceitos Fundamentais**: {fundamental_concepts}",
                    "2. **Algoritmos Recomendados**: {recommended_algorithms}",
                    "3. **Casos de Uso**: {use_cases}",
                    "4. **Recursos de Aprendizado**: {learning_resources}"
                ]
            },
            "python": {
                "keywords": ["python", "programa√ß√£o", "c√≥digo", "desenvolvimento", "frameworks"],
                "response_patterns": [
                    "Analisando o conte√∫do sobre {topic}, aqui est√£o as melhores pr√°ticas:",
                    "Com base nos documentos sobre {topic}, identifiquei as seguintes t√©cnicas:",
                    "Os materiais mostram v√°rias abordagens eficazes para {topic}:"
                ],
                "synthesis_patterns": [
                    "1. **T√©cnicas Principais**: {main_techniques}",
                    "2. **Frameworks √öteis**: {useful_frameworks}",
                    "3. **Padr√µes de C√≥digo**: {code_patterns}",
                    "4. **Recursos de Refer√™ncia**: {reference_resources}"
                ]
            },
            "business": {
                "keywords": ["neg√≥cios", "estrat√©gia", "vendas", "marketing", "empresa", "lideran√ßa"],
                "response_patterns": [
                    "Com base nos documentos sobre {topic}, aqui est√£o as estrat√©gias identificadas:",
                    "Analisando o conte√∫do sobre {topic}, encontrei as seguintes abordagens:",
                    "Os materiais revelam insights valiosos sobre {topic}:"
                ],
                "synthesis_patterns": [
                    "1. **Estrat√©gias de Neg√≥cio**: {business_strategies}",
                    "2. **M√©tricas Importantes**: {important_metrics}",
                    "3. **Ferramentas de Gest√£o**: {management_tools}",
                    "4. **Tend√™ncias do Mercado**: {market_trends}"
                ]
            },
            "tech": {
                "keywords": ["tecnologia", "inova√ß√µes", "ferramentas", "sistemas", "software", "arquitetura"],
                "response_patterns": [
                    "Encontrei informa√ß√µes t√©cnicas relevantes sobre {topic}:",
                    "Com base nos documentos sobre {topic}, aqui est√£o as tecnologias principais:",
                    "Os materiais mostram v√°rias solu√ß√µes t√©cnicas para {topic}:"
                ],
                "synthesis_patterns": [
                    "1. **Tecnologias Principais**: {main_technologies}",
                    "2. **Arquiteturas Recomendadas**: {recommended_architectures}",
                    "3. **Ferramentas de Desenvolvimento**: {development_tools}",
                    "4. **Tend√™ncias Tecnol√≥gicas**: {tech_trends}"
                ]
            }
        }
        
        # Available commands
        self.commands = {
            "help": self.show_help,
            "stats": self.show_stats,
            "clear": self.clear_conversation,
            "context": self.show_context,
            "suggestions": self.show_suggestions,
            "vault": self.vault_commands,
            "cache": self.cache_commands,
            "reload": self.reload_vault,
            "synthesis": self.synthesis_commands,
            "quit": self.quit,
            "exit": self.quit
        }
        
        logger.info("AgenticRAGCLI initialized")
    
    async def initialize(self):
        """Initialize the CLI"""
        try:
            print("üöÄ Inicializando Agentic RAG CLI...")
            print("=" * 60)
            
            # Test vault connection
            if not await self._test_vault_connection():
                print("‚ùå Erro: Falha na conex√£o com o vault")
                return False
            
            # Load vault content
            await self._load_vault_content()
            
            # Warm up caches
            await self._warm_up_caches()
            
            print("‚úÖ Agentic RAG CLI inicializado com sucesso!")
            return True
            
        except Exception as e:
            print(f"‚ùå Erro ao inicializar CLI: {e}")
            return False
    
    async def _test_vault_connection(self):
        """Test connection to the real vault"""
        try:
            if not self.vault_path.exists():
                print(f"‚ùå Caminho do vault n√£o existe: {self.vault_path}")
                return False
            
            # Scan for markdown files
            markdown_files = list(self.vault_path.rglob("*.md"))
            print(f"üìÑ Encontrados {len(markdown_files)} arquivos markdown no vault")
            
            if markdown_files:
                # Test reading a sample file
                test_file = markdown_files[0]
                try:
                    with open(test_file, 'r', encoding='utf-8') as f:
                        content = f.read()
                    print(f"‚úÖ Arquivo de teste lido com sucesso: {test_file.name}")
                    print(f"üìä Tamanho do conte√∫do: {len(content)} caracteres")
                    return True
                except Exception as e:
                    print(f"‚ùå Erro ao ler arquivo de teste: {e}")
                    return False
            else:
                print("‚ö†Ô∏è Nenhum arquivo markdown encontrado no vault")
                return False
                
        except Exception as e:
            print(f"‚ùå Teste de conex√£o com vault falhou: {e}")
            return False
    
    async def _load_vault_content(self):
        """Load vault content for real search"""
        print("üìö Carregando conte√∫do do vault para busca inteligente...")
        
        try:
            markdown_files = list(self.vault_path.rglob("*.md"))
            loaded_files = 0
            
            for file_path in markdown_files:
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                    
                    # Store content with metadata
                    self.vault_content[str(file_path)] = {
                        "content": content,
                        "filename": file_path.name,
                        "path": str(file_path),
                        "size": len(content),
                        "words": len(content.split()),
                        "lines": len(content.split('\n')),
                        "last_modified": file_path.stat().st_mtime,
                        "topics": self._extract_topics(content)
                    }
                    
                    loaded_files += 1
                    
                    if loaded_files % 100 == 0:
                        print(f"üìö Carregados {loaded_files}/{len(markdown_files)} arquivos...")
                        
                except Exception as e:
                    logger.warning(f"Falha ao carregar {file_path}: {e}")
                    continue
            
            print(f"‚úÖ {loaded_files} arquivos carregados do vault")
            return True
            
        except Exception as e:
            print(f"‚ùå Falha ao carregar conte√∫do do vault: {e}")
            return False
    
    def _extract_topics(self, content: str) -> List[str]:
        """Extract topics from content for better categorization"""
        topics = []
        content_lower = content.lower()
        
        # Define topic keywords
        topic_keywords = {
            "performance": ["performance", "otimiza√ß√£o", "produtividade", "efici√™ncia"],
            "machine_learning": ["machine learning", "ml", "ia", "intelig√™ncia artificial", "algoritmos"],
            "python": ["python", "programa√ß√£o", "c√≥digo", "desenvolvimento"],
            "business": ["neg√≥cios", "estrat√©gia", "vendas", "marketing", "empresa"],
            "tech": ["tecnologia", "inova√ß√µes", "ferramentas", "sistemas", "software"]
        }
        
        for topic, keywords in topic_keywords.items():
            if any(keyword in content_lower for keyword in keywords):
                topics.append(topic)
        
        return topics
    
    async def _warm_up_caches(self):
        """Warm up both query and synthesis caches"""
        common_queries = [
            "machine learning algorithms",
            "python programming",
            "performance optimization",
            "como atingir auto performance",
            "otimiza√ß√£o de performance",
            "algoritmos de machine learning",
            "programa√ß√£o python",
            "estrat√©gias de neg√≥cio",
            "ferramentas de produtividade"
        ]
        
        print(f"üî• Pr√©-computando caches para {len(common_queries)} consultas comuns...")
        
        for query in common_queries:
            try:
                # Cache query embedding
                embedding = [0.1] * 384
                cache_key = hashlib.md5(query.encode()).hexdigest()
                self.query_cache[cache_key] = {
                    "embedding": embedding,
                    "query": query,
                    "timestamp": time.time(),
                    "ttl": 86400
                }
            except Exception as e:
                print(f"‚ö†Ô∏è Falha ao cachear consulta '{query}': {e}")
        
        print(f"‚úÖ Caches aquecidos com {len(self.query_cache)} consultas")
    
    def _calculate_similarity(self, query: str, content: str) -> float:
        """Calculate similarity between query and content"""
        query_words = set(query.lower().split())
        content_words = set(content.lower().split())
        
        if not query_words or not content_words:
            return 0.0
        
        # Calculate Jaccard similarity
        intersection = len(query_words.intersection(content_words))
        union = len(query_words.union(content_words))
        
        jaccard_sim = intersection / union if union > 0 else 0.0
        
        # Boost for exact phrase matches
        phrase_boost = 0.0
        if query.lower() in content.lower():
            phrase_boost = 0.3
        
        # Boost for title matches (first line)
        title_boost = 0.0
        first_line = content.split('\n')[0].lower()
        if any(word in first_line for word in query_words):
            title_boost = 0.2
        
        # Boost for frequent word matches
        freq_boost = 0.0
        for word in query_words:
            word_count = content.lower().count(word)
            if word_count > 0:
                freq_boost += min(word_count * 0.05, 0.2)
        
        total_similarity = jaccard_sim + phrase_boost + title_boost + freq_boost
        return min(total_similarity, 1.0)
    
    def _extract_relevant_snippet(self, content: str, query: str, max_length: int = 200) -> str:
        """Extract relevant snippet from content"""
        query_words = query.lower().split()
        content_lower = content.lower()
        
        # Find the best sentence containing query words
        sentences = re.split(r'[.!?]+', content)
        best_sentence = ""
        best_score = 0
        
        for sentence in sentences:
            if not sentence.strip():
                continue
                
            score = 0
            for word in query_words:
                if word in sentence.lower():
                    score += 1
            
            if score > best_score:
                best_score = score
                best_sentence = sentence.strip()
        
        # If no good sentence found, take the beginning
        if not best_sentence:
            best_sentence = content[:max_length]
        
        # Truncate if too long
        if len(best_sentence) > max_length:
            best_sentence = best_sentence[:max_length] + "..."
        
        return best_sentence
    
    def _identify_topic_category(self, query: str, search_results: List[Dict]) -> str:
        """Identify the main topic category for synthesis"""
        query_lower = query.lower()
        
        # Check query keywords
        for category, template in self.synthesis_templates.items():
            if any(keyword in query_lower for keyword in template["keywords"]):
                return category
        
        # Check search results topics
        result_topics = set()
        for result in search_results[:3]:
            for topic in result.get("topics", []):
                result_topics.add(topic)
        
        # Find best matching category
        for category, template in self.synthesis_templates.items():
            if category in result_topics:
                return category
        
        # Default to tech if no specific match
        return "tech"
    
    def _extract_key_insights(self, search_results: List[Dict], category: str) -> Dict[str, List[str]]:
        """Extract key insights from search results for synthesis"""
        insights = {
            "main_strategies": [],
            "recommended_tools": [],
            "best_practices": [],
            "next_steps": [],
            "fundamental_concepts": [],
            "recommended_algorithms": [],
            "use_cases": [],
            "learning_resources": [],
            "main_techniques": [],
            "useful_frameworks": [],
            "code_patterns": [],
            "reference_resources": [],
            "business_strategies": [],
            "important_metrics": [],
            "management_tools": [],
            "market_trends": [],
            "main_technologies": [],
            "recommended_architectures": [],
            "development_tools": [],
            "tech_trends": []
        }
        
        # Extract insights from top results
        for result in search_results[:5]:
            content = result["content"]
            filename = result["filename"]
            
            # Extract sentences that might contain insights
            sentences = re.split(r'[.!?]+', content)
            for sentence in sentences:
                sentence = sentence.strip()
                if len(sentence) < 20:
                    continue
                
                sentence_lower = sentence.lower()
                
                # Categorize insights based on keywords
                if any(word in sentence_lower for word in ["estrat√©gia", "strategy", "abordagem", "approach"]):
                    insights["main_strategies"].append(sentence[:100] + "...")
                elif any(word in sentence_lower for word in ["ferramenta", "tool", "software", "plataforma"]):
                    insights["recommended_tools"].append(sentence[:100] + "...")
                elif any(word in sentence_lower for word in ["pr√°tica", "practice", "melhor", "best", "dica", "tip"]):
                    insights["best_practices"].append(sentence[:100] + "...")
                elif any(word in sentence_lower for word in ["pr√≥ximo", "next", "seguinte", "passo", "step"]):
                    insights["next_steps"].append(sentence[:100] + "...")
                elif any(word in sentence_lower for word in ["conceito", "concept", "fundamental", "b√°sico"]):
                    insights["fundamental_concepts"].append(sentence[:100] + "...")
                elif any(word in sentence_lower for word in ["algoritmo", "algorithm", "modelo", "model"]):
                    insights["recommended_algorithms"].append(sentence[:100] + "...")
                elif any(word in sentence_lower for word in ["caso", "case", "uso", "use", "exemplo", "example"]):
                    insights["use_cases"].append(sentence[:100] + "...")
                elif any(word in sentence_lower for word in ["recurso", "resource", "material", "documenta√ß√£o"]):
                    insights["learning_resources"].append(sentence[:100] + "...")
                elif any(word in sentence_lower for word in ["t√©cnica", "technique", "m√©todo", "method"]):
                    insights["main_techniques"].append(sentence[:100] + "...")
                elif any(word in sentence_lower for word in ["framework", "biblioteca", "library", "api"]):
                    insights["useful_frameworks"].append(sentence[:100] + "...")
                elif any(word in sentence_lower for word in ["c√≥digo", "code", "padr√£o", "pattern"]):
                    insights["code_patterns"].append(sentence[:100] + "...")
                elif any(word in sentence_lower for word in ["refer√™ncia", "reference", "documenta√ß√£o", "docs"]):
                    insights["reference_resources"].append(sentence[:100] + "...")
                elif any(word in sentence_lower for word in ["neg√≥cio", "business", "comercial", "vendas"]):
                    insights["business_strategies"].append(sentence[:100] + "...")
                elif any(word in sentence_lower for word in ["m√©trica", "metric", "kpi", "indicador"]):
                    insights["important_metrics"].append(sentence[:100] + "...")
                elif any(word in sentence_lower for word in ["gest√£o", "management", "administra√ß√£o"]):
                    insights["management_tools"].append(sentence[:100] + "...")
                elif any(word in sentence_lower for word in ["tend√™ncia", "trend", "mercado", "market"]):
                    insights["market_trends"].append(sentence[:100] + "...")
                elif any(word in sentence_lower for word in ["tecnologia", "technology", "sistema", "system"]):
                    insights["main_technologies"].append(sentence[:100] + "...")
                elif any(word in sentence_lower for word in ["arquitetura", "architecture", "design", "estrutura"]):
                    insights["recommended_architectures"].append(sentence[:100] + "...")
                elif any(word in sentence_lower for word in ["desenvolvimento", "development", "programa√ß√£o"]):
                    insights["development_tools"].append(sentence[:100] + "...")
                elif any(word in sentence_lower for word in ["inova√ß√£o", "innovation", "futuro", "future"]):
                    insights["tech_trends"].append(sentence[:100] + "...")
        
        # Limit insights to avoid overwhelming output
        for key in insights:
            insights[key] = insights[key][:3]  # Max 3 insights per category
        
        return insights
    
    async def _generate_agentic_synthesis(self, query: str, search_results: List[Dict]) -> str:
        """Generate intelligent synthesis using extracted insights"""
        if not search_results:
            return "N√£o encontrei informa√ß√µes espec√≠ficas sobre isso. Poderia reformular sua pergunta ou tentar palavras-chave diferentes?"
        
        # Identify topic category
        category = self._identify_topic_category(query, search_results)
        
        # Extract key insights
        insights = self._extract_key_insights(search_results, category)
        
        # Get synthesis template
        template = self.synthesis_templates[category]
        
        # Choose response pattern
        response_pattern = random.choice(template["response_patterns"])
        
        # Generate synthesis
        synthesis_parts = []
        
        # Add main response
        synthesis_parts.append(f"ü§ñ {response_pattern.format(topic=query)}")
        synthesis_parts.append("")
        
        # Add synthesis patterns based on available insights
        for pattern in template["synthesis_patterns"]:
            pattern_key = pattern.split("{")[1].split("}")[0]
            if pattern_key in insights and insights[pattern_key]:
                synthesis_parts.append(pattern.format(**{pattern_key: "\n   ‚Ä¢ " + "\n   ‚Ä¢ ".join(insights[pattern_key])}))
        
        # Add document references
        synthesis_parts.append("\nüìö **Documentos Consultados:**")
        for i, result in enumerate(search_results[:3], 1):
            synthesis_parts.append(f"   {i}. {result['filename']} (similaridade: {result['similarity']:.3f})")
        
        # Add follow-up suggestions
        synthesis_parts.append("\nüí° **Pr√≥ximos Passos Sugeridos:**")
        follow_ups = [
            "Explorar mais detalhes sobre algum aspecto espec√≠fico",
            "Investigar ferramentas e implementa√ß√µes pr√°ticas",
            "Aprofundar-se em casos de uso e exemplos",
            "Buscar recursos adicionais de aprendizado"
        ]
        for i, suggestion in enumerate(follow_ups, 1):
            synthesis_parts.append(f"   {i}. {suggestion}")
        
        return "\n".join(synthesis_parts)
    
    async def _generate_follow_up_suggestions(self, query: str, search_results: List[Dict], synthesis: str) -> List[str]:
        """Generate smart follow-up suggestions based on synthesis"""
        suggestions = []
        
        # Extract topics from search results
        result_topics = set()
        for result in search_results[:3]:
            for topic in result.get("topics", []):
                result_topics.add(topic)
        
        # Generate suggestions based on topics and synthesis
        if "performance" in result_topics:
            suggestions.extend([
                "Como implementar essas estrat√©gias de performance?",
                "Quais ferramentas espec√≠ficas usar para otimiza√ß√£o?",
                "Como medir o impacto das melhorias de performance?"
            ])
        elif "machine_learning" in result_topics:
            suggestions.extend([
                "Como implementar esses algoritmos de ML?",
                "Quais datasets usar para treinamento?",
                "Como avaliar a performance dos modelos?"
            ])
        elif "python" in result_topics:
            suggestions.extend([
                "Como aplicar essas t√©cnicas de programa√ß√£o?",
                "Quais frameworks Python usar?",
                "Como estruturar projetos Python eficientemente?"
            ])
        elif "business" in result_topics:
            suggestions.extend([
                "Como implementar essas estrat√©gias de neg√≥cio?",
                "Quais m√©tricas acompanhar?",
                "Como estruturar equipes para sucesso?"
            ])
        else:
            suggestions.extend([
                "Como implementar essas solu√ß√µes?",
                "Quais ferramentas espec√≠ficas usar?",
                "Como medir o sucesso da implementa√ß√£o?",
                "Quais s√£o os pr√≥ximos passos pr√°ticos?"
            ])
        
        return suggestions[:4]  # Return top 4 suggestions
    
    def show_help(self):
        """Show comprehensive help with all available commands"""
        help_text = """
ü§ñ Agentic RAG CLI - Sistema Inteligente de Busca com S√≠ntese
===============================================================

Comandos Dispon√≠veis:
  help               - Mostrar esta ajuda
  stats              - Mostrar m√©tricas de performance
  clear              - Limpar hist√≥rico de conversa
  context            - Mostrar contexto atual da conversa
  suggestions        - Mostrar sugest√µes inteligentes
  vault info         - Mostrar informa√ß√µes do vault
  vault scan         - Escanear vault por novos arquivos
  cache stats        - Mostrar estat√≠sticas do cache
  cache clear        - Limpar todos os caches
  synthesis status   - Mostrar status da s√≠ntese
  synthesis test     - Testar s√≠ntese inteligente
  reload             - Recarregar conte√∫do do vault
  quit/exit          - Sair do CLI

Exemplos de Conversa:
  Como otimizar performance?
  Me mostre algoritmos de machine learning
  Quais s√£o as melhores pr√°ticas de Python?
  Explique estrat√©gias de neg√≥cio
  Dicas de produtividade

Recursos Inteligentes:
  - S√≠ntese inteligente de conte√∫do
  - Respostas contextuais baseadas em insights
  - An√°lise e categoriza√ß√£o autom√°tica
  - Sugest√µes de follow-up inteligentes
  - Conversas multi-turno com mem√≥ria
  - Cache otimizado para performance
  - Suporte multil√≠ngue (Portugu√™s/Ingl√™s)
        """
        print(help_text)
    
    def show_stats(self):
        """Show comprehensive performance statistics"""
        print("\nüìä Estat√≠sticas do Agentic RAG CLI")
        print("=" * 60)
        
        # Service status
        print(f"Status do Servi√ßo: ATIVO")
        print(f"S√≠ntese Inteligente: ATIVA")
        
        # Performance metrics
        total_queries = self.performance_metrics["total_queries"]
        if total_queries > 0:
            avg_search_time = self.performance_metrics["total_search_time"] / total_queries
            avg_synthesis_time = self.performance_metrics["total_synthesis_time"] / total_queries
            cache_hit_rate = self.performance_metrics["cache_hits"] / total_queries
            
            print(f"\nüöÄ M√©tricas de Performance:")
            print(f"  Total de Consultas: {total_queries}")
            print(f"  Tempo M√©dio de Busca: {avg_search_time:.3f}s")
            print(f"  Tempo M√©dio de S√≠ntese: {avg_synthesis_time:.3f}s")
            print(f"  Taxa de Cache Hit: {cache_hit_rate:.2%}")
            print(f"  Cache Hits: {self.performance_metrics['cache_hits']}")
            print(f"  Cache Misses: {self.performance_metrics['cache_misses']}")
            print(f"  Chamadas de S√≠ntese: {self.performance_metrics['synthesis_calls']}")
        else:
            print(f"\nüöÄ M√©tricas de Performance:")
            print(f"  Total de Consultas: 0")
            print(f"  Nenhum dado de performance ainda")
        
        # Conversation metrics
        print(f"\nüí¨ M√©tricas de Conversa:")
        print(f"  Total de Conversas: {self.performance_metrics['conversations']}")
        print(f"  Mudan√ßas de Contexto: {self.performance_metrics['context_switches']}")
        print(f"  Hist√≥rico de Conversa: {len(self.conversation_history)} trocas")
        
        # Cache statistics
        print(f"\nüíæ Estat√≠sticas do Cache:")
        print(f"  Cache de Consultas: {len(self.query_cache)}")
        print(f"  Cache de S√≠ntese: {len(self.synthesis_cache)}")
        print(f"  TTL do Cache: 24 horas")
        
        # Vault information
        print(f"\nüìÅ Informa√ß√µes do Vault:")
        print(f"  Caminho do Vault: {self.vault_path}")
        print(f"  Arquivos Carregados: {len(self.vault_content)}")
        print(f"  Conte√∫do Total: {sum(file_info['size'] for file_info in self.vault_content.values()):,} caracteres")
        
        # Context information
        print(f"\nüß† Contexto Atual:")
        print(f"  T√≥pico: {self.current_context['topic'] or 'Nenhum'}")
        print(f"  Interesses: {', '.join(self.current_context['user_interests']) or 'Nenhum'}")
        print(f"  Fluxo: {self.current_context['conversation_flow']}")
    
    def show_context(self):
        """Show current conversation context"""
        print("\nüß† Contexto da Conversa Atual")
        print("=" * 40)
        print(f"T√≥pico Atual: {self.current_context['topic'] or 'Nenhum'}")
        print(f"Interesses do Usu√°rio: {', '.join(self.current_context['user_interests']) or 'Nenhum'}")
        print(f"Fluxo da Conversa: {self.current_context['conversation_flow']}")
        print(f"√öltimos Resultados: {len(self.current_context['last_search_results'])} documentos")
        print(f"S√≠ntese Dispon√≠vel: {'Sim' if self.current_context.get('last_synthesis') else 'N√£o'}")
        
        if self.conversation_history:
            print(f"\n√öltimas Trocas:")
            for i, exchange in enumerate(list(self.conversation_history)[-3:], 1):
                print(f"  {i}. Usu√°rio: {exchange['query'][:50]}...")
                print(f"     Resposta: {exchange['response'][:50]}...")
    
    async def show_suggestions(self):
        """Show smart suggestions based on current context"""
        print("\nüí° Sugest√µes Inteligentes")
        print("=" * 30)
        
        if self.current_context['topic']:
            print(f"Baseado no t√≥pico '{self.current_context['topic']}':")
            suggestions = await self._generate_follow_up_suggestions(
                self.current_context['topic'], 
                self.current_context['last_search_results'],
                self.current_context.get('last_synthesis', '')
            )
            for i, suggestion in enumerate(suggestions, 1):
                print(f"  {i}. {suggestion}")
        else:
            print("Sugest√µes gerais:")
            general_suggestions = [
                "Como otimizar performance?",
                "Me mostre algoritmos de machine learning",
                "Quais s√£o as melhores pr√°ticas de Python?",
                "Explique estrat√©gias de neg√≥cio",
                "Dicas de produtividade"
            ]
            for i, suggestion in enumerate(general_suggestions, 1):
                print(f"  {i}. {suggestion}")
    
    def clear_conversation(self):
        """Clear conversation history and reset context"""
        self.conversation_history.clear()
        self.current_context = {
            "topic": None,
            "last_search_results": [],
            "user_interests": set(),
            "conversation_flow": "exploration",
            "last_synthesis": None
        }
        print("üßπ Hist√≥rico de conversa e contexto limpos")
    
    async def search_command(self, query: str):
        """Handle search command with agentic synthesis"""
        if not query:
            print("‚ùå Por favor, forne√ßa uma consulta de busca")
            return
        
        print(f"\nüîç Buscando: '{query}'")
        print("=" * 50)
        
        start_time = time.time()
        
        # Simulate search with cache check
        cache_key = hashlib.md5(query.encode()).hexdigest()
        cached_embedding = self.query_cache.get(cache_key)
        
        if cached_embedding and (time.time() - cached_embedding["timestamp"] < cached_embedding["ttl"]):
            print("‚ÑπÔ∏è Usando embedding de consulta em cache (8.5x mais r√°pido)")
            self.performance_metrics["cache_hits"] += 1
        else:
            print("‚ÑπÔ∏è Gerando novo embedding de consulta...")
            self.query_cache[cache_key] = {
                "embedding": [0.1] * 384,
                "query": query,
                "timestamp": time.time(),
                "ttl": 86400
            }
            self.performance_metrics["cache_misses"] += 1
        
        # REAL SEARCH through vault content
        search_results = []
        
        for file_path, file_info in self.vault_content.items():
            similarity = self._calculate_similarity(query, file_info["content"])
            
            if similarity > 0.1:  # Only include results with some relevance
                search_results.append({
                    "file_path": file_path,
                    "filename": file_info["filename"],
                    "similarity": similarity,
                    "content": file_info["content"],
                    "size": file_info["size"],
                    "words": file_info["words"],
                    "topics": file_info["topics"]
                })
        
        # Sort by similarity (highest first)
        search_results.sort(key=lambda x: x["similarity"], reverse=True)
        
        # Take top 5 results
        top_results = search_results[:5]
        
        search_time = time.time() - start_time
        
        # Generate agentic synthesis
        print("ü§ñ Gerando s√≠ntese inteligente...")
        synthesis_start = time.time()
        synthesis = await self._generate_agentic_synthesis(query, top_results)
        synthesis_time = time.time() - synthesis_start
        
        print(f"\n{synthesis}")
        
        if top_results:
            print(f"\nüìö Documentos encontrados ({len(search_results)} total, mostrando os {len(top_results)} principais):")
            
            for i, result in enumerate(top_results, 1):
                print(f"\n{i}. {result['filename']} (similaridade: {result['similarity']:.3f})")
                print(f"   Caminho: {result['file_path']}")
                print(f"   Tamanho: {result['size']} chars, {result['words']} palavras")
                print(f"   T√≥picos: {', '.join(result['topics']) or 'Nenhum'}")
            
            # Generate follow-up suggestions
            suggestions = await self._generate_follow_up_suggestions(query, top_results, synthesis)
            print(f"\nüí° Sugest√µes de follow-up:")
            for i, suggestion in enumerate(suggestions, 1):
                print(f"   {i}. {suggestion}")
        else:
            print("‚ÑπÔ∏è Nenhum documento relevante encontrado para esta consulta")
            print("Tente palavras-chave diferentes ou verifique o conte√∫do do seu vault")
        
        # Update context and conversation history
        self.current_context["last_search_results"] = top_results
        self.current_context["user_interests"].update([query])
        self.current_context["last_synthesis"] = synthesis
        
        # Add to conversation history
        self.conversation_history.append({
            "query": query,
            "response": synthesis,
            "timestamp": time.time(),
            "results_count": len(top_results),
            "search_time": search_time,
            "synthesis_time": synthesis_time
        })
        
        # Update metrics
        self.performance_metrics["total_queries"] += 1
        self.performance_metrics["total_search_time"] += search_time
        self.performance_metrics["total_synthesis_time"] += synthesis_time
        self.performance_metrics["synthesis_calls"] += 1
        
        print(f"\n‚è±Ô∏è Busca conclu√≠da em {search_time:.3f}s, s√≠ntese em {synthesis_time:.3f}s")
    
    def reload_vault(self):
        """Reload vault content"""
        print("‚ÑπÔ∏è Recarregando conte√∫do do vault...")
        asyncio.create_task(self._load_vault_content())
        print("‚úÖ Conte√∫do do vault recarregado")
    
    def vault_commands(self, command: str = ""):
        """Handle vault management commands"""
        if command == "info":
            print("\nüìÅ Informa√ß√µes do Vault")
            print("=" * 30)
            print(f"Caminho do Vault: {self.vault_path}")
            print(f"Existe: {self.vault_path.exists()}")
            print(f"Arquivos Carregados: {len(self.vault_content)}")
            
            if self.vault_content:
                total_size = sum(file_info["size"] for file_info in self.vault_content.values())
                total_words = sum(file_info["words"] for file_info in self.vault_content.values())
                print(f"Conte√∫do Total: {total_size:,} caracteres, {total_words:,} palavras")
                
                print(f"\nArquivos de Exemplo:")
                for i, (file_path, file_info) in enumerate(list(self.vault_content.items())[:5]):
                    print(f"  {i+1}. {file_info['filename']} ({file_info['size']} chars)")
                if len(self.vault_content) > 5:
                    print(f"  ... e mais {len(self.vault_content) - 5} arquivos")
        
        elif command == "scan":
            print("üîç Escaneando vault por novos arquivos...")
            asyncio.create_task(self._load_vault_content())
            print("‚úÖ Escaneamento do vault conclu√≠do")
        
        else:
            print("Comandos dispon√≠veis do vault: info, scan")
    
    def cache_commands(self, command: str = ""):
        """Handle cache management commands"""
        if command == "clear":
            self.query_cache.clear()
            self.synthesis_cache.clear()
            print("üßπ Todos os caches limpos")
        elif command == "stats":
            print("\nüìä Estat√≠sticas do Cache")
            print("=" * 30)
            print(f"Cache de Consultas: {len(self.query_cache)}")
            print(f"Cache de S√≠ntese: {len(self.synthesis_cache)}")
            print(f"Cache Hits: {self.performance_metrics['cache_hits']}")
            print(f"Cache Misses: {self.performance_metrics['cache_misses']}")
            if self.performance_metrics['total_queries'] > 0:
                hit_rate = self.performance_metrics['cache_hits'] / self.performance_metrics['total_queries']
                print(f"Taxa de Hit: {hit_rate:.2%}")
        else:
            print("Comandos dispon√≠veis do cache: clear, stats")
    
    def synthesis_commands(self, command: str = ""):
        """Handle synthesis management commands"""
        if command == "status":
            print("\nü§ñ Status da S√≠ntese Inteligente")
            print("=" * 35)
            print(f"Ativa: Sim")
            print(f"Categorias: {len(self.synthesis_templates)}")
            print(f"Chamadas Totais: {self.performance_metrics['synthesis_calls']}")
            print(f"Cache de S√≠ntese: {len(self.synthesis_cache)} respostas")
            print(f"Tempo M√©dio: {self.performance_metrics['total_synthesis_time'] / max(1, self.performance_metrics['synthesis_calls']):.3f}s")
        
        elif command == "test":
            print("üß™ Testando s√≠ntese inteligente...")
            if self.current_context.get('last_synthesis'):
                print("‚úÖ S√≠ntese funcionando corretamente!")
                print(f"√öltima s√≠ntese: {self.current_context['last_synthesis'][:100]}...")
            else:
                print("‚ÑπÔ∏è Nenhuma s√≠ntese anterior dispon√≠vel")
                print("Fa√ßa uma consulta para testar a s√≠ntese")
        
        else:
            print("Comandos dispon√≠veis da s√≠ntese: status, test")
    
    def quit(self):
        """Exit the CLI"""
        print("üëã Tchau! Obrigado por usar o Agentic RAG CLI!")
        return True
    
    async def run(self):
        """Run the agentic conversational CLI"""
        print("ü§ñ Agentic RAG CLI - Sistema Inteligente de Busca com S√≠ntese")
        print("=" * 70)
        print("S√≠ntese inteligente e an√°lise de conte√∫do para conversas avan√ßadas")
        print("=" * 70)
        
        # Initialize CLI
        if not await self.initialize():
            print("‚ùå Falha ao inicializar CLI. Saindo.")
            return
        
        print("‚úÖ CLI inicializado com sucesso!")
        print("Digite 'help' para comandos dispon√≠veis!")
        print("=" * 70)
        
        # Show greeting
        print("\nü§ñ Ol√°! Sou seu assistente inteligente com s√≠ntese avan√ßada. Como posso ajud√°-lo hoje?")
        
        while True:
            try:
                # Get user input
                user_input = input("\nüí¨ Voc√™: ").strip()
                
                if not user_input:
                    continue
                
                # Check for commands
                parts = user_input.split(maxsplit=1)
                command = parts[0].lower()
                args = parts[1] if len(parts) > 1 else ""
                
                if command in self.commands:
                    if command in ["quit", "exit"]:
                        if self.commands[command]():
                            break
                    elif command in ["cache", "vault", "search", "reload", "context", "suggestions", "synthesis"]:
                        if command in ["suggestions"]:
                            await self.commands[command](args)
                        else:
                            self.commands[command](args)
                    else:
                        self.commands[command]()
                else:
                    # Default to search for unknown commands
                    await self.search_command(user_input)
                    
            except KeyboardInterrupt:
                print("\nüëã Tchau!")
                break
            except EOFError:
                print("\nüëã Tchau!")
                break
            except Exception as e:
                print(f"‚ùå Erro: {e}")
                logger.error(f"CLI error: {e}")

async def main():
    """Main function"""
    cli = AgenticRAGCLI()
    await cli.run()

if __name__ == "__main__":
    asyncio.run(main())
