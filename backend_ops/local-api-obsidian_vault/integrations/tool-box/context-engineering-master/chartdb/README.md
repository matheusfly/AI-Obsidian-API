# ChartDB Documentation Scraper

Advanced web scraping system for ChartDB database visualization tool with MCP integration, performance optimization, and comprehensive documentation extraction.

## ğŸ¯ Overview

This scraper system extracts comprehensive documentation and features from ChartDB, including:
- Database diagram templates
- Interactive visualization features
- Documentation and tutorials
- API references and examples
- GitHub repository content

## ğŸš€ Features

### Core Scraping Capabilities
- **Multi-Engine Support**: Scrapfly, Playwright, Scrapy, Requests
- **JavaScript Rendering**: Full SPA support for dynamic content
- **Anti-Detection**: Advanced evasion techniques
- **Rate Limiting**: Intelligent request throttling
- **Error Recovery**: Robust retry mechanisms

### ChartDB-Specific Features
- **Diagram Extraction**: Database ERD and schema diagrams
- **Template Collection**: Pre-built diagram templates
- **Feature Analysis**: Interactive visualization capabilities
- **Documentation Mining**: Complete docs coverage
- **Screenshot Capture**: Visual documentation

### MCP Integration
- **Real-time Processing**: Live scraping with MCP servers
- **Context Management**: Context7 integration
- **Performance Monitoring**: Advanced metrics and analytics
- **Distributed Processing**: Multi-server coordination

## ğŸ“ Project Structure

```
chartdb-docs-scraper/
â”œâ”€â”€ README.md                    # This file
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.py             # Configuration settings
â”œâ”€â”€ mcp_servers/
â”‚   â”œâ”€â”€ chartdb_mcp_server.py   # ChartDB MCP server
â”‚   â””â”€â”€ context7_mcp_server.py  # Context7 integration
â”œâ”€â”€ scrapers/
â”‚   â”œâ”€â”€ base_scraper.py         # Base scraper class
â”‚   â”œâ”€â”€ chartdb_scraper.py      # ChartDB-specific scraper
â”‚   â”œâ”€â”€ playwright_scraper.py   # Playwright implementation
â”‚   â””â”€â”€ scrapfly_scraper.py     # Scrapfly implementation
â”œâ”€â”€ flows/
â”‚   â”œâ”€â”€ chartdb_visual_flow.flyde    # Visual scraping flow
â”‚   â””â”€â”€ diagram_extraction.flyde     # Diagram extraction flow
â”œâ”€â”€ web_ui/
â”‚   â”œâ”€â”€ main.py                 # FastAPI web interface
â”‚   â”œâ”€â”€ templates/              # HTML templates
â”‚   â””â”€â”€ static/                 # CSS/JS assets
â”œâ”€â”€ data/                       # Scraped data storage
â”‚   â”œâ”€â”€ diagrams/               # Extracted diagrams
â”‚   â”œâ”€â”€ templates/              # Diagram templates
â”‚   â””â”€â”€ documentation/          # Documentation files
â””â”€â”€ scripts/
    â”œâ”€â”€ launch_chartdb.ps1      # PowerShell launcher
    â””â”€â”€ test_scraper.py         # Test scripts
```

## ğŸ›  Installation

### Prerequisites
- Python 3.9+
- Node.js 18+ (for Flyde flows)
- PowerShell 7+ (for Windows)

### Quick Setup
```powershell
# Navigate to project directory
cd tool-box\chartdb-docs-scraper

# Run setup script
.\scripts\launch_chartdb.ps1 -Setup
```

### Manual Setup
```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Install Node.js dependencies
npm install

# Run the scraper
python main.py
```

## ğŸ® Usage

### Command Line Interface
```bash
# Basic scraping
python main.py --url https://chartdb.io/

# Advanced scraping with options
python main.py --url https://chartdb.io/ --engine playwright --extract-diagrams --screenshot

# Full documentation crawl
python main.py --crawl-all --output-format json --compress
```

### Web Interface
```bash
# Start web UI
python web_ui/main.py

# Access at http://localhost:8002
```

### Flyde Visual Flows
```bash
# Run visual scraping flow
node flows/run_chartdb_flow.js

# Or use PowerShell
.\scripts\launch_chartdb.ps1 -Flow
```

## ğŸ”§ Configuration

### Environment Variables
```bash
# Scrapfly API (optional)
SCRAPFLY_API_KEY=your_api_key

# Context7 API (optional)
CONTEXT7_API_KEY=your_api_key

# Database connection
DATABASE_URL=postgresql://user:pass@localhost:5432/chartdb_docs

# Performance settings
MAX_CONCURRENT_REQUESTS=20
REQUEST_DELAY=0.5
TIMEOUT=30
```

### Settings File
Edit `config/settings.py` to customize:
- Target URLs
- Scraping engines
- Output formats
- Performance parameters
- MCP server configurations

## ğŸ“Š Target URLs

### Primary Targets
- **Main Site**: https://chartdb.io/
- **Templates**: https://chartdb.io/templates
- **GitHub**: https://github.com/chartdb/chartdb
- **Documentation**: https://chartdb.io/docs (if available)

### Secondary Targets
- **API Documentation**: https://chartdb.io/api
- **Examples**: https://chartdb.io/examples
- **Blog**: https://chartdb.io/blog (if available)

## ğŸ¨ Flyde Visual Flows

### ChartDB Visual Flow
Visual representation of the scraping process:
1. **Trigger**: Start scraping process
2. **URL Discovery**: Find all ChartDB URLs
3. **Content Extraction**: Extract diagrams and templates
4. **Data Processing**: Process and structure data
5. **Storage**: Save to database and files
6. **Visualization**: Display results

### Diagram Extraction Flow
Specialized flow for diagram extraction:
1. **Page Analysis**: Analyze page structure
2. **Diagram Detection**: Find diagram elements
3. **Template Extraction**: Extract diagram templates
4. **Schema Analysis**: Analyze database schemas
5. **Documentation**: Generate documentation

## ğŸ” MCP Integration

### ChartDB MCP Server
- **scrape_chartdb**: Main scraping function
- **extract_database_diagrams**: Extract diagrams from content
- **extract_templates**: Extract diagram templates
- **analyze_database_schema**: Analyze database schemas
- **generate_schema_documentation**: Generate documentation

### Context7 Integration
- **Context Management**: Store and retrieve scraping context
- **Knowledge Graph**: Build knowledge relationships
- **Semantic Search**: Find related content
- **Version Control**: Track changes over time

## ğŸ“ˆ Performance Features

### Optimization
- **Concurrent Processing**: Multi-threaded scraping
- **Caching**: Intelligent content caching
- **Compression**: Data compression for storage
- **Rate Limiting**: Respectful scraping practices

### Monitoring
- **Real-time Metrics**: Live performance monitoring
- **Error Tracking**: Comprehensive error logging
- **Progress Tracking**: Visual progress indicators
- **Resource Usage**: Memory and CPU monitoring

## ğŸ§ª Testing

### Test Suite
```bash
# Run all tests
python -m pytest tests/

# Run specific test
python -m pytest tests/test_chartdb_scraper.py

# Run with coverage
python -m pytest --cov=scrapers tests/
```

### Test Scripts
```bash
# Quick functionality test
python scripts/test_scraper.py

# Performance test
python scripts/performance_test.py

# Integration test
python scripts/integration_test.py
```

## ğŸš€ Deployment

### Local Development
```bash
# Start all services
.\scripts\launch_chartdb.ps1 -All

# Start specific service
.\scripts\launch_chartdb.ps1 -WebUI
.\scripts\launch_chartdb.ps1 -MCP
.\scripts\launch_chartdb.ps1 -Scraper
```

### Production Deployment
```bash
# Docker deployment
docker-compose up -d

# Kubernetes deployment
kubectl apply -f k8s/

# Cloud deployment
.\scripts\deploy_cloud.ps1
```

## ğŸ“š Documentation

### Generated Documentation
- **API Reference**: Complete API documentation
- **User Guide**: Step-by-step usage guide
- **Developer Guide**: Technical implementation details
- **Troubleshooting**: Common issues and solutions

### Data Outputs
- **JSON**: Structured data export
- **Markdown**: Human-readable documentation
- **HTML**: Interactive documentation
- **CSV**: Tabular data export

## ğŸ¤ Contributing

### Development Setup
1. Fork the repository
2. Create feature branch
3. Make changes
4. Add tests
5. Submit pull request

### Code Standards
- **Python**: PEP 8 compliance
- **Type Hints**: Full type annotation
- **Documentation**: Comprehensive docstrings
- **Testing**: 90%+ test coverage

## ğŸ“„ License

MIT License - see LICENSE file for details.

## ğŸ†˜ Support

### Troubleshooting
- Check logs in `logs/` directory
- Review configuration in `config/settings.py`
- Run diagnostic script: `python scripts/diagnose.py`

### Getting Help
- **Issues**: GitHub Issues
- **Discussions**: GitHub Discussions
- **Documentation**: Project Wiki
- **Community**: Discord/Telegram

## ğŸ”„ Updates

### Version History
- **v1.0.0**: Initial release with basic scraping
- **v1.1.0**: Added MCP integration
- **v1.2.0**: Added Flyde visual flows
- **v1.3.0**: Added web UI and advanced features

### Roadmap
- **v1.4.0**: Advanced AI processing
- **v1.5.0**: Cloud deployment support
- **v2.0.0**: Multi-tool integration platform

---

**Built with â¤ï¸ for the ChartDB community**